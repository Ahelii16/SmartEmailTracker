{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRCS8lZB4w3o"
   },
   "source": [
    "# Few-Shot Learning Email Classification with Pre-Trained Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyqSa0W9MAth"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import seed\n",
    "from random import sample\n",
    "from wordfile import func\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import spatial\n",
    "import os\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "5vn8VEhgMAtm",
    "outputId": "7baa3702-bf5f-43a9-ebec-5fb77396808c"
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open('/home/aheli/glove.6B.300d.txt',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coeffs = np.asarray(values[1:],dtype='float32')\n",
    "        embeddings_index[word] = coeffs\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "Te79WnJnNpt5",
    "outputId": "dcf855f3-f2a8-4ff9-f160-192c099a03eb"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "Ww7cY-xAMAtq",
    "outputId": "13c525e7-7a88-414f-88fb-66ea445815f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transaction no. 072558 is unresolved.</td>\n",
       "      <td>Sorry to inform that there has been only a par...</td>\n",
       "      <td>Pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Order for new Cheque book</td>\n",
       "      <td>Good morning, I want to place an order for an ...</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Required money acquired. Transaction 847047 is...</td>\n",
       "      <td>Hello! This is to inform you that I have recei...</td>\n",
       "      <td>Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asking for the details for transaction 746078</td>\n",
       "      <td>I request you to kindly send the status of my ...</td>\n",
       "      <td>Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Partial payment for transaction 535918</td>\n",
       "      <td>Hello!! Greetings for the day. Status of trans...</td>\n",
       "      <td>Pending</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject  \\\n",
       "0              Transaction no. 072558 is unresolved.   \n",
       "1                          Order for new Cheque book   \n",
       "2  Required money acquired. Transaction 847047 is...   \n",
       "3      Asking for the details for transaction 746078   \n",
       "4             Partial payment for transaction 535918   \n",
       "\n",
       "                                                Body       Class  \n",
       "0  Sorry to inform that there has been only a par...     Pending  \n",
       "1  Good morning, I want to place an order for an ...     General  \n",
       "2  Hello! This is to inform you that I have recei...  Processing  \n",
       "3  I request you to kindly send the status of my ...     Request  \n",
       "4  Hello!! Greetings for the day. Status of trans...     Pending  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./emaildataset.csv\", usecols = ['Subject','Body', 'Class'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGKMNx5SkOEl"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L_jS9wVPkuXK"
   },
   "outputs": [],
   "source": [
    "my_stop = [\"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\",'a','cc','subject','http', 'gbp', 'usd', 'eur', 'inr', 'cad', 'thanks', \"acc\", \"id\", 'account', 'regards', 'hi', 'hello', 'thank you', 'greetings', 'about','above', 'across','after','afterwards','alone','along','am','among', 'amongst','amount','an','and','another','any','anyhow','anyone','anything','anyway','anywhere','are','around','as', 'at','be','became','because','become','becomes','becoming','been','before','beforehand','behind','being','below', 'beside','besides','between','both','bottom','but','by','ca','call','can','could','did', 'do', 'does', 'doing', 'down', 'due', 'during', 'each', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'everyone', 'everything', 'everywhere', 'fifteen', 'fifty', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'four', 'from', 'front', 'further', 'get', 'give', 'go', 'had', 'has', 'have', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'if', 'in', 'indeed', 'into', 'is', 'it', 'its', 'itself', 'just', 'keep', 'last', 'latter', 'latterly', 'least', 'less', 'made', 'make', 'many', 'may', 'me', 'meanwhile', 'might', 'mine', 'more', 'moreover', 'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'nevertheless', 'next', 'nine', 'no', 'nobody', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'one', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'quite', 'rather', 're', 'really', 'regarding', 'same', 'say', 'see', 'seem', 'seemed', 'seeming', 'seems', 'she', 'should', 'show', 'side', 'since', 'six', 'sixty', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'somewhere', 'such', 'take', 'ten', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'third', 'this', 'those', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards', 'twelve', 'twenty', 'two', 'under', 'up', 'upon', 'us', 'using', 'various', 'via', 'was', 'we', 'well', 'were', 'whatever', 'whence', 'whenever', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'whoever', 'whole', 'whom', 'whose', 'will', 'with', 'within', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves', '‘d', '‘ll', '‘m', '‘re', '‘s', '‘ve', '’d', '’ll', '’m', '’re', '’s', '’ve']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToyHfo1oMAtv"
   },
   "outputs": [],
   "source": [
    "def get_only_chars(text):    \n",
    "    text = text.replace(\"-\", \" \") #replace hyphens with spaces\n",
    "    text = text.replace(\"\\t\", \" \")\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    text=text.rstrip()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    t = \"\"\n",
    "\n",
    "    for i in text.lower().split():\n",
    "        if func(i) is not None:\n",
    "            t += func(i) + \" \"\n",
    "        else :\n",
    "            t += i + \" \"\n",
    "\n",
    "    t = t.rstrip()\n",
    "    \n",
    "    text = \" \".join([i for i in t.lower().split()])\n",
    "    text = \" \".join(token for token in text.split() if token not in my_stop)\n",
    "\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    doc = \" \".join(token.orth_ for token in doc if not token.is_punct | token.is_space)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "want info legal entity\n"
     ]
    }
   ],
   "source": [
    "print(get_only_chars(\"hi i want info on le 12234.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-ewz3NnMAtz"
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    # merge subject and body strings\n",
    "    df['Text'] = (df['Subject'] + \" \" + df['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7vrpfOTlZAm"
   },
   "outputs": [],
   "source": [
    "def converter(x):\n",
    "    try:\n",
    "        return ' '.join([x.lower() for x in str(x).split()])\n",
    "    except AttributeError:\n",
    "        return None  # or some other value\n",
    "\n",
    "df['Text'] = df['Text'].apply(converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QHCB4AnXlfgP"
   },
   "outputs": [],
   "source": [
    "text_clean=[]\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    text_clean.append(get_only_chars(df.loc[i]['Text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWsuPQTaMAt3"
   },
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(lambda x: get_only_chars(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9EbusUWvMAuA"
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates('Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "qyGor_mYMAuI",
    "outputId": "7ec29a95-ed6f-4038-b533-656c4e2f88dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fulfilled transaction having ID : 400122</td>\n",
       "      <td>Greetings! I wanted to let you know that I hav...</td>\n",
       "      <td>Complete</td>\n",
       "      <td>fulfilled transaction having wanted let know a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finalized transaction of ID : 014482</td>\n",
       "      <td>I deeply appreciate your quick service as I ha...</td>\n",
       "      <td>Complete</td>\n",
       "      <td>finalized transaction deeply appreciate quick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Impetrating details for ID : 003473</td>\n",
       "      <td>Hey, I would be really grateful if you could t...</td>\n",
       "      <td>Request</td>\n",
       "      <td>impetrating details hey grateful tell details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Change address for account no. 872684</td>\n",
       "      <td>I need a new cheque book of 25 leaves. Kindly ...</td>\n",
       "      <td>General</td>\n",
       "      <td>change address need new cheque book leaves kin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imploring update on transaction : 276292</td>\n",
       "      <td>I request you to kindly send the status of my ...</td>\n",
       "      <td>Request</td>\n",
       "      <td>imploring update transaction request kindly se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>issue a new Cheque book</td>\n",
       "      <td>Warm greetings to you. I have recently exhaust...</td>\n",
       "      <td>General</td>\n",
       "      <td>issue new cheque book warm recently exhausted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>New Cheque book</td>\n",
       "      <td>I need a new cheque book of 25 leaves. Kindly ...</td>\n",
       "      <td>General</td>\n",
       "      <td>new cheque book need new cheque book leaves ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Payment outstanding for transaction 255828</td>\n",
       "      <td>Hello!! Greetings for the day. Status of trans...</td>\n",
       "      <td>Pending</td>\n",
       "      <td>payment outstanding transaction day status tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Abrupt closure of transaction with ID 868876</td>\n",
       "      <td>This is in response to your email stating that...</td>\n",
       "      <td>Failed</td>\n",
       "      <td>abrupt closure transaction response email stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Send steps to activate online banking</td>\n",
       "      <td>Hey, I have to transfer funds to a different b...</td>\n",
       "      <td>General</td>\n",
       "      <td>send steps activate online banking hey transfe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Subject  \\\n",
       "0        Fulfilled transaction having ID : 400122   \n",
       "1            Finalized transaction of ID : 014482   \n",
       "2             Impetrating details for ID : 003473   \n",
       "3           Change address for account no. 872684   \n",
       "4        Imploring update on transaction : 276292   \n",
       "..                                            ...   \n",
       "350                       issue a new Cheque book   \n",
       "351                               New Cheque book   \n",
       "352    Payment outstanding for transaction 255828   \n",
       "353  Abrupt closure of transaction with ID 868876   \n",
       "354         Send steps to activate online banking   \n",
       "\n",
       "                                                  Body     Class  \\\n",
       "0    Greetings! I wanted to let you know that I hav...  Complete   \n",
       "1    I deeply appreciate your quick service as I ha...  Complete   \n",
       "2    Hey, I would be really grateful if you could t...   Request   \n",
       "3    I need a new cheque book of 25 leaves. Kindly ...   General   \n",
       "4    I request you to kindly send the status of my ...   Request   \n",
       "..                                                 ...       ...   \n",
       "350  Warm greetings to you. I have recently exhaust...   General   \n",
       "351  I need a new cheque book of 25 leaves. Kindly ...   General   \n",
       "352  Hello!! Greetings for the day. Status of trans...   Pending   \n",
       "353  This is in response to your email stating that...    Failed   \n",
       "354  Hey, I have to transfer funds to a different b...   General   \n",
       "\n",
       "                                                  Text  \n",
       "0    fulfilled transaction having wanted let know a...  \n",
       "1    finalized transaction deeply appreciate quick ...  \n",
       "2        impetrating details hey grateful tell details  \n",
       "3    change address need new cheque book leaves kin...  \n",
       "4    imploring update transaction request kindly se...  \n",
       "..                                                 ...  \n",
       "350  issue new cheque book warm recently exhausted ...  \n",
       "351  new cheque book need new cheque book leaves ki...  \n",
       "352  payment outstanding transaction day status tra...  \n",
       "353  abrupt closure transaction response email stat...  \n",
       "354  send steps activate online banking hey transfe...  \n",
       "\n",
       "[355 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g33n-rxSMAuL"
   },
   "outputs": [],
   "source": [
    "# set the by default to:\n",
    "num_classes = df.Class.unique() # the number of classes we consider (since the dataset has many classes)\n",
    "sample_size = 5 # the number of labeled sampled we’ll require from the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "smallest_sample_size = min(df['Class'].value_counts())\n",
    "print(smallest_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sR36GBuvMAua"
   },
   "outputs": [],
   "source": [
    "# Generate samples that contains K samples of each class\n",
    "\n",
    "def gen_sample(sample_size, num_classes, df):\n",
    "    \n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    df_1 = df[(df[\"Class\"] < num_classes+1)].reset_index().drop([\"index\"], axis=1).reset_index().drop([\"index\"], axis=1)\n",
    "    \n",
    "    train = df_1[df_1[\"Class\"] == np.unique(df_1['Class'])[0]].sample(sample_size)\n",
    "    train_index = train.index.tolist()\n",
    "\n",
    "    for i in range(1,num_classes):\n",
    "        train_2 = df_1[df_1[\"Class\"] == np.unique(df_1['Class'])[i]].sample(sample_size)\n",
    "        train = pd.concat([train, train_2], axis=0)\n",
    "        train_index.extend(train_2.index.tolist())\n",
    "\n",
    "    test = df_1[~df_1.index.isin(train_index)]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUQujqKaMAuT"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Class'] = le.fit_transform(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transaction no. 072558 is unresolved.</td>\n",
       "      <td>Sorry to inform that there has been only a par...</td>\n",
       "      <td>3</td>\n",
       "      <td>transaction unresolved sorry inform only parti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Order for new Cheque book</td>\n",
       "      <td>Good morning, I want to place an order for an ...</td>\n",
       "      <td>2</td>\n",
       "      <td>order new cheque book good morning want place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Required money acquired. Transaction 847047 is...</td>\n",
       "      <td>Hello! This is to inform you that I have recei...</td>\n",
       "      <td>4</td>\n",
       "      <td>required money acquired transaction process in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asking for the details for transaction 746078</td>\n",
       "      <td>I request you to kindly send the status of my ...</td>\n",
       "      <td>5</td>\n",
       "      <td>asking details transaction request kindly send...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Partial payment for transaction 535918</td>\n",
       "      <td>Hello!! Greetings for the day. Status of trans...</td>\n",
       "      <td>3</td>\n",
       "      <td>partial payment transaction day status transac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Payment done and Transaction 683241 settled.</td>\n",
       "      <td>Greetings! I wanted to let you know that I hav...</td>\n",
       "      <td>0</td>\n",
       "      <td>payment done transaction settled wanted let kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Failure of transaction 608189</td>\n",
       "      <td>This is to notify you that my transaction 6081...</td>\n",
       "      <td>1</td>\n",
       "      <td>failure transaction notify transaction failed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Send steps to activate online banking</td>\n",
       "      <td>Hey, I have to transfer funds to a different b...</td>\n",
       "      <td>2</td>\n",
       "      <td>send steps activate online banking hey transfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Incomplete transaction 947071</td>\n",
       "      <td>I regret to inform you that I could only pay t...</td>\n",
       "      <td>3</td>\n",
       "      <td>incomplete transaction regret inform only pay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Failure of transaction 443004</td>\n",
       "      <td>Hey, I see my transaction with ID 443004 has f...</td>\n",
       "      <td>1</td>\n",
       "      <td>failure transaction hey transaction failed thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The pending amount for transaction 537615 will...</td>\n",
       "      <td>Since my transaction 537615 is still pending, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>pending transaction reach soon transaction sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Handling the transaction 682817 after payment.</td>\n",
       "      <td>Sincere greetings, I am glad to tell you that ...</td>\n",
       "      <td>4</td>\n",
       "      <td>handling transaction payment sincere glad tell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Upgrade to an account with more benefits</td>\n",
       "      <td>Hello, greetings for the day, So I have an acc...</td>\n",
       "      <td>2</td>\n",
       "      <td>upgrade benefits day branch having recently se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Processing transaction having ID : 064742</td>\n",
       "      <td>Acknowledging the received payment for transac...</td>\n",
       "      <td>4</td>\n",
       "      <td>processing transaction having acknowledging re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>issue a new Cheque book</td>\n",
       "      <td>Warm greetings to you. I have recently exhaust...</td>\n",
       "      <td>2</td>\n",
       "      <td>issue new cheque book warm recently exhausted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The pending amount for transaction 376023 will...</td>\n",
       "      <td>I regret to inform you the I could only pay th...</td>\n",
       "      <td>3</td>\n",
       "      <td>pending transaction reach soon regret inform o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Transaction having ID : 155325 has stopped. Help!</td>\n",
       "      <td>I have been your regular client and have follo...</td>\n",
       "      <td>1</td>\n",
       "      <td>transaction having stopped help regular client...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Change address for account no. 090514</td>\n",
       "      <td>Hey, It's me again. This time I want to change...</td>\n",
       "      <td>2</td>\n",
       "      <td>change address hey s again time want change ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Partially paid the required amount for transac...</td>\n",
       "      <td>There has been only a partial payment of amoun...</td>\n",
       "      <td>3</td>\n",
       "      <td>partially paid required transaction only parti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>there is an outstanding payment for transactio...</td>\n",
       "      <td>The transaction 981293 is taking too long to c...</td>\n",
       "      <td>3</td>\n",
       "      <td>outstanding payment transaction transaction ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Subject  \\\n",
       "0               Transaction no. 072558 is unresolved.   \n",
       "1                           Order for new Cheque book   \n",
       "2   Required money acquired. Transaction 847047 is...   \n",
       "3       Asking for the details for transaction 746078   \n",
       "4              Partial payment for transaction 535918   \n",
       "5        Payment done and Transaction 683241 settled.   \n",
       "6                       Failure of transaction 608189   \n",
       "7               Send steps to activate online banking   \n",
       "8                       Incomplete transaction 947071   \n",
       "9                       Failure of transaction 443004   \n",
       "10  The pending amount for transaction 537615 will...   \n",
       "11     Handling the transaction 682817 after payment.   \n",
       "12           Upgrade to an account with more benefits   \n",
       "13          Processing transaction having ID : 064742   \n",
       "14                            issue a new Cheque book   \n",
       "15  The pending amount for transaction 376023 will...   \n",
       "16  Transaction having ID : 155325 has stopped. Help!   \n",
       "17              Change address for account no. 090514   \n",
       "18  Partially paid the required amount for transac...   \n",
       "19  there is an outstanding payment for transactio...   \n",
       "\n",
       "                                                 Body  Class  \\\n",
       "0   Sorry to inform that there has been only a par...      3   \n",
       "1   Good morning, I want to place an order for an ...      2   \n",
       "2   Hello! This is to inform you that I have recei...      4   \n",
       "3   I request you to kindly send the status of my ...      5   \n",
       "4   Hello!! Greetings for the day. Status of trans...      3   \n",
       "5   Greetings! I wanted to let you know that I hav...      0   \n",
       "6   This is to notify you that my transaction 6081...      1   \n",
       "7   Hey, I have to transfer funds to a different b...      2   \n",
       "8   I regret to inform you that I could only pay t...      3   \n",
       "9   Hey, I see my transaction with ID 443004 has f...      1   \n",
       "10  Since my transaction 537615 is still pending, ...      3   \n",
       "11  Sincere greetings, I am glad to tell you that ...      4   \n",
       "12  Hello, greetings for the day, So I have an acc...      2   \n",
       "13  Acknowledging the received payment for transac...      4   \n",
       "14  Warm greetings to you. I have recently exhaust...      2   \n",
       "15  I regret to inform you the I could only pay th...      3   \n",
       "16  I have been your regular client and have follo...      1   \n",
       "17  Hey, It's me again. This time I want to change...      2   \n",
       "18  There has been only a partial payment of amoun...      3   \n",
       "19  The transaction 981293 is taking too long to c...      3   \n",
       "\n",
       "                                                 Text  \n",
       "0   transaction unresolved sorry inform only parti...  \n",
       "1   order new cheque book good morning want place ...  \n",
       "2   required money acquired transaction process in...  \n",
       "3   asking details transaction request kindly send...  \n",
       "4   partial payment transaction day status transac...  \n",
       "5   payment done transaction settled wanted let kn...  \n",
       "6   failure transaction notify transaction failed ...  \n",
       "7   send steps activate online banking hey transfe...  \n",
       "8   incomplete transaction regret inform only pay ...  \n",
       "9   failure transaction hey transaction failed thi...  \n",
       "10  pending transaction reach soon transaction sti...  \n",
       "11  handling transaction payment sincere glad tell...  \n",
       "12  upgrade benefits day branch having recently se...  \n",
       "13  processing transaction having acknowledging re...  \n",
       "14  issue new cheque book warm recently exhausted ...  \n",
       "15  pending transaction reach soon regret inform o...  \n",
       "16  transaction having stopped help regular client...  \n",
       "17  change address hey s again time want change ad...  \n",
       "18  partially paid required transaction only parti...  \n",
       "19  outstanding payment transaction transaction ta...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    75\n",
       "5    72\n",
       "3    66\n",
       "0    52\n",
       "1    49\n",
       "4    41\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['Complete']\n",
      "1\n",
      "['Failed']\n",
      "2\n",
      "['General']\n",
      "3\n",
      "['Pending']\n",
      "4\n",
      "['Processing']\n",
      "5\n",
      "['Request']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 6):\n",
    "    print(i)\n",
    "    print(le.inverse_transform([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "es3wgR_pMAu7"
   },
   "outputs": [],
   "source": [
    "def transform_sentence(text, embeddings_index):\n",
    "\n",
    "    def preprocess_text(raw_text, model=embeddings_index):\n",
    "\n",
    "        raw_text = raw_text.split()\n",
    "        return list(filter(lambda x: x in embeddings_index.keys(), raw_text))\n",
    "\n",
    "    tokens = preprocess_text(text)\n",
    "\n",
    "    if not tokens:\n",
    "        return np.zeros(300)\n",
    "\n",
    "    c = [embeddings_index[i] for i in tokens]\n",
    "    text_vector = np.mean(c, axis=0)\n",
    "    return np.array(text_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./pkl_objects/labelencoder.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists('./pkl_objects'):\n",
    "        os.mkdir('./pkl_objects')\n",
    "    \n",
    "joblib.dump(le, './pkl_objects/labelencoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77gBGCTLlJwa"
   },
   "source": [
    "## Pre-trained Glove embeddings and ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZjDXuv9wqDoa"
   },
   "outputs": [],
   "source": [
    "# Install with below cell if you're not able to install on terminal\n",
    "\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfjwlGRjMAvk"
   },
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ihouEwYNCyn"
   },
   "outputs": [],
   "source": [
    "def return_score_xgb(sample_size, num_classes, df):\n",
    "\n",
    "    train, test = gen_sample(sample_size, num_classes, df=df)\n",
    "\n",
    "    X_train = train['Text'].values\n",
    "    y_train = train['Class'].values\n",
    "    X_test = test['Text'].values\n",
    "    y_test = test['Class'].values\n",
    "\n",
    "    X_train_mean = np.array([transform_sentence(x, embeddings_index) for x in X_train])\n",
    "    X_test_mean = np.array([transform_sentence(x, embeddings_index) for x in X_test])\n",
    "\n",
    "#     XG Boost\n",
    "    clf = xgboost.XGBClassifier()\n",
    "    \n",
    "    eval_set = [(X_train_mean, y_train), (X_test_mean, y_test)]\n",
    "    eval_metric = [\"auc\",\"error\", \"logloss\"]\n",
    "    %time clf.fit(X_train_mean, y_train, early_stopping_rounds=10, eval_metric=eval_metric, eval_set=eval_set, verbose=True)\n",
    "\n",
    "\n",
    "#     clf.fit(X_train_mean, y_train)\n",
    "    joblib.dump(clf, './pkl_objects/clf_xgb.pkl')\n",
    "\n",
    "    y_pred = clf.predict(X_test_mean)\n",
    "    \n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "    return accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def return_score(sample_size, num_classes, df):\n",
    "\n",
    "#     train, test = gen_sample(sample_size, num_classes, df=df)\n",
    "\n",
    "#     X_train = train['Text'].values\n",
    "#     y_train = train['Class'].values\n",
    "#     X_test = test['Text'].values\n",
    "#     y_test = test['Class'].values\n",
    "\n",
    "#     X_train_mean = np.array([transform_sentence(x, embeddings_index) for x in X_train])\n",
    "#     X_test_mean = np.array([transform_sentence(x, embeddings_index) for x in X_test])\n",
    "\n",
    "# #     XG Boost\n",
    "#     clf = xgboost.XGBClassifier()\n",
    "    \n",
    "#     eval_set = [(X_train_mean, y_train), (X_test_mean, y_test)]\n",
    "#     eval_metric = [\"auc\",\"error\"]\n",
    "#     %time clf.fit(X_train_mean, y_train, early_stopping_rounds=10, eval_metric=eval_metric, eval_set=eval_set, verbose=True)\n",
    "    \n",
    "# #     clf.fit(X_train_mean, y_train)\n",
    "\n",
    "#     joblib.dump(clf, './pkl_objects/clf.pkl')\n",
    "\n",
    "#     y_pred = clf.predict(X_test_mean)\n",
    "    \n",
    "#     # evaluate predictions\n",
    "#     accuracy = accuracy_score(y_pred, y_test)\n",
    "#     print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "#     return accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LOzNWHqP3X9"
   },
   "source": [
    "## Comparison of accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_accuracy = {10: [], 40: []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def retrain(df):\n",
    "#     num_classes = len(df.Class.unique())\n",
    "#     smallest_sample_size = min(df['Class'].value_counts())\n",
    "#     if smallest_sample_size >= 10 && smallest_sample_size < 41:\n",
    "#         all_accuracy[10].append(return_score(10,smallest_sample_size, df=df))\n",
    "#     else if smallest_sample_size >= 41:\n",
    "#         for num_samples in range(1, 42):\n",
    "#             all_accuracy[40].append(return_score_xgb(num_samples,smallest_sample_size, df=df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num_samples in range(1, 10):\n",
    "#     all_accuracy[0].append(return_score(num_samples,len(df.Class.unique()), df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,8))\n",
    "# plt.plot(all_accuracy[0])\n",
    "# # plt.axvline(7, c='black', alpha=0.5)\n",
    "\n",
    "# plt.title(\"Accuracy depending on the number of samples for XG Boost algorithm\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jUHYGi8nIphJ"
   },
   "outputs": [],
   "source": [
    "# df_results = pd.DataFrame({\n",
    "    \n",
    "#     'Nb Classes':[6], \n",
    "\n",
    "#     'mean XG Boost':[np.mean(all_accuracy[0])], \n",
    "#     'max XG Boost':[\n",
    "#         max(all_accuracy[0])]\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    798\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight_eval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                         nthread=self.n_jobs)\n\u001b[0;32m--> 800\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m             )\n\u001b[1;32m    802\u001b[0m             \u001b[0mnevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    798\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight_eval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                         nthread=self.n_jobs)\n\u001b[0;32m--> 800\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m             )\n\u001b[1;32m    802\u001b[0m             \u001b[0mnevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[0;32m---> 53\u001b[0;31m                              % str(diff))\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [2]"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-deb12bc3eecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum_cl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mall_accuracy_xgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_cl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_score_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_cl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-e65d084f4daa>\u001b[0m in \u001b[0;36mreturn_score_xgb\u001b[0;34m(sample_size, num_classes, df)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./pkl_objects/clf_xgb.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# evaluate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mntree_limit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0mntree_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_ntree_limit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m         class_probs = self.get_booster().predict(\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0mtest_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_Booster'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to call fit or load_model beforehand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "all_accuracy_xgb = {2:[],3:[],4:[],5:[],6:[]}\n",
    "\n",
    "for num_samples in range(1, 40):\n",
    "\n",
    "    for num_cl in range(2, 7):\n",
    "\n",
    "        all_accuracy_xgb[num_cl].append(return_score_xgb(num_samples,num_cl, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    \n",
    "    'Nb Classes':[2, 3, 4, 5, 6], \n",
    "\n",
    "    'mean XG Boost':[np.mean(all_accuracy_xgb[2]), \n",
    "        np.mean(all_accuracy_xgb[3]), \n",
    "        np.mean(all_accuracy_xgb[4]), \n",
    "        np.mean(all_accuracy_xgb[5]),\n",
    "        np.mean(all_accuracy_xgb[6])],\n",
    "    'max XG Boost':[max(all_accuracy_xgb[2]), \n",
    "        max(all_accuracy_xgb[3]), \n",
    "        max(all_accuracy_xgb[4]), \n",
    "        max(all_accuracy_xgb[5]),\n",
    "        max(all_accuracy_xgb[6])]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "colab_type": "code",
    "id": "633I-hFqoURr",
    "outputId": "10de37e2-eef5-4696-f035-ec04cc157c6e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(all_accuracy_xgb[2], label=\"2 classes\")\n",
    "plt.plot(all_accuracy_xgb[3], label=\"3 classes\")\n",
    "plt.plot(all_accuracy_xgb[4], label=\"4 classes\")\n",
    "plt.plot(all_accuracy_xgb[5], label=\"5 classes\")\n",
    "plt.plot(all_accuracy_xgb[6], label=\"6 classes\")\n",
    "plt.axvline(7, c='black', alpha=0.5)\n",
    "\n",
    "plt.title(\"Accuracy depending on the number of classes for XG Boost algorithm\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# plt.savefig('accuracy_plot.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on incoming email "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = joblib.load('./pkl_objects/labelencoder.pkl')\n",
    "clf = joblib.load('./pkl_objects/clf_xgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_empty_sent(cd):\n",
    "    all_zeros = not cd.any()\n",
    "    return all_zeros\n",
    "\n",
    "print(is_empty_sent(transform_sentence(\"efrg vftrg ojinc\", embeddings_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp(emailto, emailfrom, subj, bod):\n",
    "    text = subj + \" \" + bod\n",
    "    text = get_only_chars(text)\n",
    "    X_test_mean = np.array([transform_sentence(text, embeddings_index)])\n",
    "    \n",
    "    if is_empty_sent(X_test_mean) is True:\n",
    "        print(\"Unable to read email.Please ensure that it is in English!\")\n",
    "        return\n",
    "\n",
    "    y_pred = clf.predict(X_test_mean)\n",
    "    print(y_pred)\n",
    "\n",
    "    return le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inp(\"fvf\", \"defrfg\", \"payment processed\", \"hi, the payment for acc 1234 for usd 3456 was paid successfully.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inp(\"cfdfv\", \"derftrg\", \"Partially paid the required amount for transaction\", \"There has been only a partial payment of amount 1234\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Word2vec_KNN_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
