{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, email,re\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set_style('whitegrid')\n",
    "import wordcloud\n",
    "\n",
    "# Network analysis\n",
    "import networkx as nx\n",
    "\n",
    "# NLP\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "from subprocess import check_output\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517401, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df = pd.read_csv('./compressed_emails.csv/emails.csv')\n",
    "print(emails_df.shape)\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "def get_text_from_email(msg):\n",
    "    '''To get the content from email objects'''\n",
    "    parts = []\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            parts.append( part.get_payload() )\n",
    "    return ''.join(parts)\n",
    "\n",
    "def split_email_addresses(line):\n",
    "    '''To separate multiple email addresses'''\n",
    "    if line:\n",
    "        addrs = line.split(',')\n",
    "        addrs = frozenset(map(lambda x: x.strip(), addrs))\n",
    "    else:\n",
    "        addrs = None\n",
    "    return addrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Mime-Version</th>\n",
       "      <th>Content-Type</th>\n",
       "      <th>Content-Transfer-Encoding</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-Origin</th>\n",
       "      <th>X-FileName</th>\n",
       "      <th>content</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>&lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(tim.belden@enron.com)</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen (Non-Privileged).pst</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>&lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(john.lavorato@enron.com)</td>\n",
       "      <td>Re:</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>John J Lavorato &lt;John J Lavorato/ENRON@enronXg...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen (Non-Privileged).pst</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>&lt;24216240.1075855687451.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(leah.arsdall@enron.com)</td>\n",
       "      <td>Re: test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Leah Van Arsdall</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen.nsf</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>&lt;13505866.1075863688222.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(randall.gay@enron.com)</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Randall L Gay</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen.nsf</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>&lt;30922949.1075863688243.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(greg.piper@enron.com)</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Greg Piper</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen.nsf</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                     Message-ID  \\\n",
       "0     allen-p/_sent_mail/1.  <18782981.1075855378110.JavaMail.evans@thyme>   \n",
       "1    allen-p/_sent_mail/10.  <15464986.1075855378456.JavaMail.evans@thyme>   \n",
       "2   allen-p/_sent_mail/100.  <24216240.1075855687451.JavaMail.evans@thyme>   \n",
       "3  allen-p/_sent_mail/1000.  <13505866.1075863688222.JavaMail.evans@thyme>   \n",
       "4  allen-p/_sent_mail/1001.  <30922949.1075863688243.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    Date                       From  \\\n",
       "0  Mon, 14 May 2001 16:39:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "1   Fri, 4 May 2001 13:51:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "2  Wed, 18 Oct 2000 03:00:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "3  Mon, 23 Oct 2000 06:13:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "4  Thu, 31 Aug 2000 05:07:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "\n",
       "                          To    Subject Mime-Version  \\\n",
       "0     (tim.belden@enron.com)                     1.0   \n",
       "1  (john.lavorato@enron.com)        Re:          1.0   \n",
       "2   (leah.arsdall@enron.com)   Re: test          1.0   \n",
       "3    (randall.gay@enron.com)                     1.0   \n",
       "4     (greg.piper@enron.com)  Re: Hello          1.0   \n",
       "\n",
       "                   Content-Type Content-Transfer-Encoding           X-From  \\\n",
       "0  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "1  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "2  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "3  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "4  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "\n",
       "                                                X-To X-cc X-bcc  \\\n",
       "0           Tim Belden <Tim Belden/Enron@EnronXGate>              \n",
       "1  John J Lavorato <John J Lavorato/ENRON@enronXg...              \n",
       "2                                   Leah Van Arsdall              \n",
       "3                                      Randall L Gay              \n",
       "4                                         Greg Piper              \n",
       "\n",
       "                                            X-Folder X-Origin  \\\n",
       "0  \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...  Allen-P   \n",
       "1  \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...  Allen-P   \n",
       "2    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail  Allen-P   \n",
       "3    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail  Allen-P   \n",
       "4    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail  Allen-P   \n",
       "\n",
       "                    X-FileName  \\\n",
       "0  pallen (Non-Privileged).pst   \n",
       "1  pallen (Non-Privileged).pst   \n",
       "2                   pallen.nsf   \n",
       "3                   pallen.nsf   \n",
       "4                   pallen.nsf   \n",
       "\n",
       "                                             content     user  \n",
       "0                          Here is our forecast\\n\\n   allen-p  \n",
       "1  Traveling to have a business meeting takes the...  allen-p  \n",
       "2                     test successful.  way to go!!!  allen-p  \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...  allen-p  \n",
       "4                Let's shoot for Tuesday at 11:45.    allen-p  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse the emails into a list email objects\n",
    "messages = list(map(email.message_from_string, emails_df['message']))\n",
    "emails_df.drop('message', axis=1, inplace=True)\n",
    "# Get fields from parsed email objects\n",
    "keys = messages[0].keys()\n",
    "for key in keys:\n",
    "    emails_df[key] = [doc[key] for doc in messages]\n",
    "# Parse content from emails\n",
    "emails_df['content'] = list(map(get_text_from_email, messages))\n",
    "# Split multiple email addresses\n",
    "emails_df['From'] = emails_df['From'].map(split_email_addresses)\n",
    "emails_df['To'] = emails_df['To'].map(split_email_addresses)\n",
    "\n",
    "# Extract the root of 'file' as 'user'\n",
    "emails_df['user'] = emails_df['file'].map(lambda x:x.split('/')[0])\n",
    "del messages\n",
    "\n",
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index and drop columns with two few values\n",
    "emails_df = emails_df.set_index('Message-ID')\\\n",
    "    .drop(['file', 'Mime-Version', 'Content-Type', 'Content-Transfer-Encoding'], axis=1)\n",
    "# Parse datetime\n",
    "emails_df['Date'] = pd.to_datetime(emails_df['Date'], infer_datetime_format=True)\n",
    "emails_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    stop = set(stopwords.words('english'))\n",
    "    stop.update((\"to\",\"cc\",\"subject\",\"http\",\"from\",\"sent\",\"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"))\n",
    "    exclude = set(string.punctuation) \n",
    "    lemma = WordNetLemmatizer()\n",
    "    porter= PorterStemmer()\n",
    "    \n",
    "    text=text.rstrip()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    stop_free = \" \".join([i for i in text.lower().split() if((i not in stop) and (not i.isdigit()))])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    #stem = \" \".join(porter.stem(token) for token in normalized.split())\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df=emails_df[['From', 'To', 'Date','content']].dropna().copy()\n",
    "analysis_df = analysis_df.loc[analysis_df['To'].map(len) == 1]\n",
    "sub_df=analysis_df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_df[\"content\"]=sub_df[\"content\"].map(clean)\n",
    "text_clean=[]\n",
    "for text in sub_df['content']:\n",
    "    text_clean.append(clean(text).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(text_clean)\n",
    "text_term_matrix = [dictionary.doc2bow(text) for text in text_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldamodel = Lda(text_term_matrix, num_topics=4, id2word = dictionary, passes=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    #text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    words = text.lower().split()\n",
    "    words = [w for w in words if w not in eng_stopwords]\n",
    "    return ' '.join(words)\n",
    "\n",
    "analysis_df[\"clean_content\"]=analysis_df.content.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvector = TfidfVectorizer(analyzer='word', stop_words='english', max_df=0.4, min_df=5)\n",
    "short_analysis=analysis_df.sample(5000)\n",
    "wordvector_fit = wordvector.fit_transform(short_analysis.clean_content)\n",
    "feature = wordvector.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "clf = KMeans(n_clusters=N, \n",
    "            max_iter=50, \n",
    "            init='k-means++', \n",
    "            n_init=1)\n",
    "labels = clf.fit_predict(wordvector_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvector_fit_2d = wordvector_fit.todense()\n",
    "pca = PCA(n_components=2).fit(wordvector_fit_2d)\n",
    "datapoint = pca.transform(wordvector_fit_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [\"#e05f14\", \"#e0dc14\", \"#2fe014\", \"#14d2e0\"]\n",
    "color = [label[i] for i in labels]\n",
    "plt.scatter(datapoint[:, 0], datapoint[:, 1], c=color)\n",
    "\n",
    "centroids = clf.cluster_centers_\n",
    "centroidpoint = pca.transform(centroids)\n",
    "plt.scatter(centroidpoint[:, 0], centroidpoint[:, 1], marker='^', s=150, c='#000000')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ldamodel.print_topics(num_topics=4, num_words=10))\n",
    "print([(0, '0.012*\"enron\" + 0.012*\"deal\" + 0.010*\"agreement\" + 0.008*\"change\" + 0.008*\"contract\" + 0.008*\"corp\" + 0.007*\"fax\" + 0.005*\"houston\" + 0.005*\"date\" + 0.005*\"america\"'), (1, '0.005*\"message\" + 0.005*\"origin\" + 0.004*\"pleas\" + 0.004*\"email\" + 0.004*\"thank\" + 0.003*\"attach\" + 0.003*\"file\" + 0.003*\"copy\" + 0.003*\"inform\" + 0.003*\"receive\"'), (2, '0.015*\"thank\" + 0.008*\"call\" + 0.005*\"time\" + 0.004*\"meet\" + 0.003*\"look\" + 0.003*\"week\" + 0.003*\"day\" + 0.003*\"lunch\" + 0.003*\"talk\" + 0.003*\"hello\"'), (3, '0.016*\"market\" + 0.009*\"gas\" + 0.008*\"price\" + 0.005*\"power\" + 0.004*\"company\" + 0.004*\"energy\" + 0.003*\"business\" + 0.003*\"service\" + 0.003*\"manage\" + 0.003*\"fare\"')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
